name: Email Automation Scheduler

on:
  schedule:
    - cron: '*/5 * * * *'  # Changed to every 5 minutes (GitHub best practice)
  workflow_dispatch:

jobs:
  run-email-agent:
    runs-on: ubuntu-latest
    
    # ðŸŒŸ NEW: Define the Ollama Service Container
    services:
      ollama_service:
        image: ollama/ollama:latest
        ports:
          - 11434:11434
        # CRITICAL FIX: The robust single-line options ensure Docker start success.
        options: --name ollama_service --health-cmd "ollama -v" --health-interval 10s --health-timeout 5s --health-retries 5

    env:
      EMAIL_ADDRESS: ${{ secrets.EMAIL_ADDRESS }}
      EMAIL_PASSWORD: ${{ secrets.EMAIL_PASSWORD }}
      LANGCHAIN_API_KEY: ${{ secrets.LANGCHAIN_API_KEY }} 
      # Optional, but good practice to define the target model
      LLM_MODEL: mixtral 

    steps:
      - name: Checkout Code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'

      - name: Install Dependencies
        run: |
          pip install requests imapclient

      # ðŸŒŸ Pull the Ollama model before running the script
      - name: Pull Ollama Model (Mixtral)
        # Added a 10s sleep to let Ollama start fully before the pull command
        run: |
          echo "Waiting 10s for Ollama service to fully initialize..."
          sleep 10
          docker exec ollama_service ollama pull mixtral
        
      # ðŸŒŸ Wait for Ollama service to be fully ready
      - name: Wait for Ollama to be available
        uses: nev7n/wait_for_response@v1
        with:
          url: http://ollama_service:11434/
          responseCode: 200
          timeout: 300 # Give it up to 5 minutes to start and pull the model
          
      - name: Run Email Agent
        # The Python script is now configured to use the local Ollama service.
        run: python email_agent.py
